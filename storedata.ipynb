{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import psycopg2, time\n",
    "from cleanup import clean\n",
    "\n",
    "# Make connection to database\n",
    "connection = psycopg2.connect(\n",
    "    user = \"athanar\",\n",
    "    host = \"localhost\",\n",
    "    port = \"5432\",\n",
    "    database = \"datascience\")\n",
    "connection.set_client_encoding('UTF8')\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "start_time = time.time()\n",
    "reader = pd.read_csv(\n",
    "    \"1mio-raw.csv\", \n",
    "    encoding='utf-8', \n",
    "    chunksize=10000)\n",
    "\n",
    "# Read SQL file\n",
    "def executeScriptFromFile(filename):\n",
    "    fd = open(filename, 'r')\n",
    "    sqlFile = fd.read()\n",
    "    fd.close()\n",
    "    sqlCommands = sqlFile.split(';')\n",
    "    for command in sqlCommands:\n",
    "        try:\n",
    "            cursor.execute(command)\n",
    "        except:\n",
    "            continue  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storedata():\n",
    "    # Variables:\n",
    "    # Sets\n",
    "    new_keywords = set()\n",
    "    new_domains = set()\n",
    "    new_authors = set()\n",
    "\n",
    "    # Lists \n",
    "    new_types = []\n",
    "    \n",
    "    # Inserts dataframe into database\n",
    "    def insertTable(cols, vals, target):\n",
    "        try: \n",
    "            sql = \"INSERT INTO \"+target+\" (\" +cols + \") VALUES (\" + \"%s,\"*(len(vals.iloc[0])-1) + \"%s)\"\n",
    "            cursor.executemany(sql, vals.values.tolist())\n",
    "            connection.commit()\n",
    "        except Exception as e:\n",
    "            print(\"Something went wrong with: %s %s\" % (target, str(e)))\n",
    "\n",
    "    # Get typeid for type string\n",
    "    def typeLookup(typeval):\n",
    "        if (isinstance(typeval, float)):\n",
    "            return 12\n",
    "        else:\n",
    "            return new_types.index(typeval) + 1\n",
    "\n",
    "    # Extract comma separated parts of string column\n",
    "    def extractParts(ids, column):\n",
    "        tmp_dict = {}\n",
    "        tmp = []\n",
    "        for i in range(len(column)):\n",
    "            if (isinstance(column.iloc[i], float)):\n",
    "                tmp.extend(str(column.iloc[i]))\n",
    "                tmp_dict[ids.iloc[i]] =  str(column.iloc[i])\n",
    "            elif (column.iloc[i] == \"[\\'\\']\"):\n",
    "                continue\n",
    "            else:\n",
    "                new_vals = (column.iloc[i]\n",
    "                            .replace('[', '')\n",
    "                            .replace(']', '')\n",
    "                            .replace('\\'', '')\n",
    "                            .replace('\\\"', '')\n",
    "                            .lower()\n",
    "                            .split(', '))\n",
    "                tmp.extend(new_vals)\n",
    "                tmp_dict[ids.iloc[i]] = new_vals\n",
    "        return set(tmp), tmp_dict\n",
    "    \n",
    "    i = 1\n",
    "    for data in reader:\n",
    "        # Size; Highly temporary for testing purposes. Can be adjusted to test smaller dataset\n",
    "        if (i > 500):\n",
    "            break\n",
    "        try:\n",
    "            # Clean data\n",
    "            data['id'] = pd.to_numeric(data['id'], errors='coerce')\n",
    "            data = data[data['id'].notna()]\n",
    "            data['content'] = data['content'].apply(clean)\n",
    "            data['title'] = data['title'].apply(clean)\n",
    "            data['summary'] = data['summary'].apply(clean)\n",
    "        except Exception as e:\n",
    "            print(\"Cleaning went wrong in round: %s %s\" % (i, str(e)))\n",
    "        \n",
    "        try:\n",
    "            # Fetches article from dataframe\n",
    "            article = data.iloc[:,[1,9,5,15,6,7,8]]\n",
    "            articleval = \"articleID, title, content, summary, scrapedAt, insertedAt, updatedAt\"\n",
    "            insertTable(articleval, article, \"Article\")\n",
    "        except Exception as e:\n",
    "            print(\"Article insertion went wrong in round: %s %s\" % (i, str(e)))\n",
    "            \n",
    "        # Fetches types from dataframe, done like this as the first round \n",
    "        # finds all relevant types \n",
    "        if (len(new_types) < 1):\n",
    "            types = data['type'].drop_duplicates().dropna()\n",
    "            typeframe = pd.DataFrame(types).rename(columns={'type':'typeValue'})\n",
    "            new_types = list(types)\n",
    "            insertTable(\"typeValue\", pd.DataFrame(types), \"Types\") \n",
    "            \n",
    "        try:\n",
    "            # Fills Typelinks\n",
    "            articleid = data.iloc[:,[1]]\n",
    "            typeid = data['type'].apply(typeLookup)\n",
    "            typelinks = pd.concat([articleid, typeid], axis=1, ignore_index=True)\n",
    "            insertTable(\"articleID, typeID\", typelinks, \"Typelinks\")\n",
    "        except Exception as e:\n",
    "            print(\"Typelinks insertion went wrong in round:%s %s\" % (i, str(e)))\n",
    "        \n",
    "        try: \n",
    "            # Fetches keywords from dataframe and inserts new keywords\n",
    "            keywords, keyword_dict = extractParts(data['id'],data['meta_keywords'])\n",
    "            keyword_list = list(keywords.difference(new_keywords))\n",
    "            new_keywords = new_keywords.union(keywords)\n",
    "            if (len(keyword_list) > 0):\n",
    "                insertTable(\"keywordValue\", pd.DataFrame(keyword_list), \"Keyword\")\n",
    "        except Exception as e:\n",
    "            print(\"Keywords insertion went wrong in round: %s %s\" % (i, str(e)))\n",
    "        \n",
    "        try: \n",
    "            # Inserts tags\n",
    "            tmp_kw = []\n",
    "            key_checker = list(new_keywords)\n",
    "            for k, v in keyword_dict.items():\n",
    "                for kword in v:\n",
    "                    tmp_kw.append([k, key_checker.index(kword)+1])\n",
    "            insertTable(\"articleID, keywordID\", pd.DataFrame(tmp_kw), \"Tags\")\n",
    "        except Exception as e:\n",
    "            print(\"Tags insertion went wrong in round: %s %s\" % (i, str(e)))\n",
    "        \n",
    "        try:\n",
    "            # Fetches domain from dataframe and inserts new domains\n",
    "            domain = set(data.loc[:,'domain'])\n",
    "            domain_list = list(domain.difference(new_domains))\n",
    "            new_domains = new_domains.union(domain)\n",
    "            if (len(domain_list) > 0):\n",
    "                insertTable(\"domainURL\", pd.DataFrame(domain_list), \"Domain\")\n",
    "        except Exception as e:\n",
    "            print(\"Domain insertion went wrong in round: %s %s\" % (i, str(e)))\n",
    "        \n",
    "        try:\n",
    "            # Fetches webpageURL from dataframe and inserts\n",
    "            dom_list = list(new_domains)\n",
    "            new_webs = data['domain'].apply(lambda x: dom_list.index(x)+1)\n",
    "            dom_frame = pd.DataFrame(\n",
    "                {'id': data['id'], 'domain': new_webs, 'url': data['url']})\n",
    "            insertTable(\"articleID, domainID, webpageurl\", dom_frame, \"Webpage\")\n",
    "        except Exception as e:\n",
    "            print(\"Webpage insertion went wrong in round: %s %s\" % (i, str(e)))\n",
    "        \n",
    "        try:\n",
    "            # Fetches authors from dataframe and inserts new authors\n",
    "            authors, authors_dict = extractParts(data['id'], data['authors'])\n",
    "            author_list = list(authors.difference(new_authors))\n",
    "            new_authors = new_authors.union(authors)\n",
    "            if (len(author_list) > 0):\n",
    "                insertTable(\"authorName\", pd.DataFrame(author_list), \"Author\")\n",
    "        except Exception as e:\n",
    "            print(\"Authors insertion went wrong in round: %s %s\" % (i, str(e)))\n",
    "        \n",
    "        try:\n",
    "            # Inserts into writtenby\n",
    "            tmp_aut = []\n",
    "            aut_checker = list(new_authors)\n",
    "            for k, v in authors_dict.items():\n",
    "                for kword in v:\n",
    "                    tmp_aut.append([k, aut_checker.index(kword)+1])\n",
    "            insertTable(\"articleID, authorID\", pd.DataFrame(tmp_aut), \"WrittenBy\")\n",
    "        except Exception as e:\n",
    "            print(\"Writtenby insertion went wrong in round: %s %s\" % (i, str(e)))\n",
    "        \n",
    "        # Round counter for timing\n",
    "        print(\"Round %d took %s seconds\" % (i,time.time() - start_time))\n",
    "        i = i+1\n",
    "\n",
    "    print(\"Finished. Took %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query():\n",
    "    # Read SQL file\n",
    "    def executeScriptFromFile(filename):\n",
    "        fd = open(filename, 'r')\n",
    "        sqlFile = fd.read()\n",
    "        fd.close()\n",
    "        sqlCommands = sqlFile.split(';')\n",
    "        for command in sqlCommands:\n",
    "            try:\n",
    "                cursor.execute(command)\n",
    "                print(pd.DataFrame(cursor.fetchall()))\n",
    "            except:\n",
    "                continue \n",
    "\n",
    "    executeScriptFromFile('queries.sql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#executeScriptFromFile('create_tables.sql')\n",
    "#storedata()\n",
    "#query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
